Initial validation loss: 8.5167673032934
  0%|                                                                                                                                                         | 0/15 [00:00<?, ?it/s]
Train loss: 8.525835037231445
Train loss: 8.321930885314941
Train loss: 7.529290437698364
Train loss: 7.9593260288238525
Train loss: 8.555665874481202
Train loss: 8.385159158706665
Train loss: 8.090631532669068
Train loss: 8.354067373275758
Train loss: 9.481590938568115
Train loss: 8.397758722305298
Train loss: 9.422602224349976
Train loss: 9.252730560302734
Train loss: 9.604275989532471
Train loss: 9.896178436279296
Train loss: 9.594962978363037
Train loss: 11.319102573394776
Train loss: 10.029603147506714
Train loss: 10.201530456542969
Train loss: 9.972728395462036
Train loss: 9.365349102020264
Train loss: 10.041256189346313
Train loss: 10.615158176422119
Train loss: 9.760767126083374
Train loss: 9.365089273452758
Train loss: 10.803303146362305
Train loss: 11.43280520439148
Train loss: 10.885120296478272
Train loss: 10.72697582244873
Train loss: 9.935182571411133
Train loss: 10.65848774909973
Train loss: 12.498402500152588
Train loss: 10.994789791107177
Train loss: 9.36318416595459
Train loss: 10.876154804229737
Train loss: 9.326648139953614
Train loss: 10.44013204574585
Train loss: 10.71253080368042
Train loss: 11.35192575454712
Train loss: 10.492337465286255
Train loss: 10.764046001434327
Train loss: 10.17448034286499
Train loss: 10.109139585494995
Train loss: 10.762541389465332
Train loss: 10.502363586425782
Train loss: 11.080685043334961
Train loss: 10.093520307540894
Train loss: 9.283250093460083
Train loss: 11.111898946762086
Train loss: 10.857912921905518
Train loss: 11.271664142608643
Epoch 1, Loss: 9.880212480068208, Val Loss: 10.80939554604617, Time Elapsed: 8.74
Train loss: 9.157034873962402
Train loss: 11.827795791625977
Train loss: 11.404396438598633
Train loss: 9.93430290222168
Train loss: 10.767822647094727
Train loss: 10.924908685684205
Train loss: 9.391363763809204
Train loss: 9.939401626586914
Train loss: 9.210290622711181
Train loss: 11.423352193832397
Train loss: 11.16728105545044
Train loss: 10.003711986541749
Train loss: 11.460839223861694
Train loss: 10.009756422042846
Train loss: 11.285205698013305
Train loss: 11.713815402984618
Train loss: 10.932895183563232
Train loss: 11.5026349067688
Train loss: 9.244997453689574
Train loss: 10.132463455200195
Train loss: 10.023875045776368
Train loss: 10.319142723083496
Train loss: 11.011696004867554
Train loss: 11.281192207336426
Train loss: 11.989829540252686
Train loss: 10.519890451431275
Train loss: 11.08512749671936
Train loss: 10.10203447341919
Train loss: 10.276907444000244
Train loss: 12.104179096221923
Train loss: 11.74116382598877
Train loss: 12.025570392608643
Train loss: 10.495755767822265
Train loss: 11.030925035476685
Train loss: 12.681465196609498
Train loss: 9.86605191230774
Train loss: 12.814883184432983
Train loss: 10.090286684036254
Train loss: 11.203907537460328
Train loss: 10.445937347412109
Train loss: 10.635250186920166
Train loss: 10.361887693405151
Train loss: 9.188565254211426
Train loss: 10.550882720947266
Train loss: 10.936776638031006
Train loss: 9.91161298751831
Train loss: 10.694070625305176
Train loss: 9.751060295104981
Train loss: 10.781372165679931
Train loss: 10.515063190460205
Epoch 2, Loss: 10.644110537624359, Val Loss: 10.756096043153242, Time Elapsed: 8.71
Train loss: 11.263299942016602
Train loss: 11.672575092315673
Train loss: 10.089379596710206
Train loss: 12.535015678405761
Train loss: 10.953325653076172
Train loss: 9.72277603149414
Train loss: 10.236042690277099
Train loss: 10.643032264709472
Train loss: 10.935762882232666
Train loss: 12.504587602615356
Train loss: 11.826186084747315
Train loss: 11.590406942367554
Train loss: 11.34326467514038
Train loss: 10.938656616210938
Train loss: 10.005050706863404
Train loss: 12.011178588867187
Train loss: 11.965020656585693
Train loss: 10.258384180068969
Train loss: 12.718112659454345
Train loss: 10.549539041519164
Train loss: 11.944896602630616
Train loss: 9.510115766525269
Train loss: 10.487056064605714
Train loss: 11.056137657165527
Train loss: 10.436168241500855
Train loss: 12.461793375015258
Train loss: 10.525499391555787
Train loss: 10.120714998245239
Train loss: 10.514864587783814
Train loss: 11.757142257690429
Train loss: 12.435844135284423
Train loss: 12.039962863922119
Train loss: 11.579989528656006
Train loss: 12.4122820854187
Train loss: 10.51876449584961
Train loss: 11.002973318099976
Train loss: 11.915354299545289
Train loss: 12.609372520446778
Train loss: 10.141402530670167
Train loss: 11.894961977005005
Train loss: 10.713062286376953
Train loss: 10.34285283088684
Train loss: 10.63155689239502
Train loss: 9.779780387878418
Train loss: 10.594087028503418
Train loss: 11.190179252624512
Train loss: 12.145446825027467
Train loss: 10.577862071990968
Train loss: 10.194635486602783
Train loss: 12.424611377716065
Epoch 3, Loss: 10.824884620857238, Val Loss: 10.86463200525804, Time Elapsed: 8.72
Train loss: 13.497861862182617
Train loss: 13.40793228149414
Train loss: 10.919720363616943
Train loss: 9.635967588424682
Train loss: 11.143764972686768
Train loss: 10.7747407913208
Train loss: 10.064886379241944
Train loss: 13.064926910400391
Train loss: 11.439207935333252
Train loss: 11.428590011596679
Train loss: 11.885802364349365
Train loss: 10.330505752563477
Train loss: 10.47557225227356
Train loss: 10.996950912475587
Train loss: 11.388847160339356
Train loss: 10.019427680969239
Train loss: 10.982549667358398
Train loss: 11.820839405059814
Train loss: 9.784454917907714
Train loss: 10.435393047332763
Train loss: 11.387523078918457
Train loss: 10.906895160675049
Train loss: 9.616452074050903
Train loss: 9.327811479568481
Train loss: 10.260617637634278
Train loss: 9.501918268203735
Train loss: 9.643757724761963
Train loss: 11.916696929931641
Train loss: 11.503070640563966
Train loss: 9.914700269699097
Train loss: 9.944711303710937
Train loss: 11.270118618011475
Train loss: 11.190858745574952
Train loss: 10.713109970092773
Train loss: 9.444993162155152
Train loss: 9.841145467758178
Train loss: 10.58822603225708
Train loss: 11.581414127349854
Train loss: 11.348176860809327
Train loss: 9.37699580192566
Train loss: 9.423366689682007
Train loss: 11.375427865982056
Train loss: 11.56896185874939
Train loss: 11.396345472335815
Train loss: 10.683791160583496
Train loss: 10.16672396659851
Train loss: 10.100777673721314
Train loss: 11.438783979415893
Train loss: 12.422892856597901
Train loss: 11.905197048187256
Epoch 4, Loss: 10.838911075496673, Val Loss: 10.93476083798842, Time Elapsed: 8.73
Train loss: 16.822175979614258
Train loss: 11.010731506347657
Train loss: 9.987405729293823
Train loss: 11.359435176849365
Train loss: 10.201453828811646
Train loss: 10.515765714645386
Train loss: 11.085199451446533
Train loss: 11.151632690429688
Train loss: 10.531175994873047
Train loss: 10.754854869842529
Train loss: 11.471241903305053
Train loss: 10.395296001434327
Train loss: 10.556108951568604
Train loss: 10.841879749298096
Train loss: 10.987576961517334
Train loss: 10.035851907730102
Train loss: 10.714660882949829
Train loss: 8.756814527511597
Train loss: 9.997442770004273
Train loss: 9.586445140838624
Train loss: 10.670178937911988
Train loss: 11.5122398853302
Train loss: 11.027732372283936
Train loss: 10.89023323059082
Train loss: 10.691900300979615
Train loss: 10.7152569770813
Train loss: 9.97749490737915
Train loss: 11.368263816833496
Train loss: 10.860061693191529
Train loss: 11.350589656829834
Train loss: 10.690074777603149
Train loss: 9.926740312576294
Train loss: 10.813769721984864
Train loss: 11.089419746398926
Train loss: 12.034230995178223
Train loss: 10.395679330825805
Train loss: 11.807444524765014
Train loss: 10.778573703765868
Train loss: 9.599194860458374
Train loss: 11.623347187042237
Train loss: 11.840726566314697
Train loss: 11.44458703994751
Train loss: 8.992387008666991
Train loss: 11.882553863525391
Train loss: 10.042443132400512
Train loss: 11.225343179702758
Train loss: 10.425612640380859
Train loss: 12.732379055023193
Train loss: 11.358276271820069
Train loss: 10.867635202407836
Epoch 5, Loss: 10.942869629383088, Val Loss: 11.136082680008629, Time Elapsed: 8.75
Train loss: 8.487358093261719
Train loss: 10.549980401992798
Train loss: 12.100064945220947
Train loss: 9.909324645996094
Train loss: 12.677166938781738
Train loss: 12.126291084289551
Train loss: 10.086595249176025
Train loss: 10.9179771900177
Train loss: 11.723744010925293
Train loss: 12.786714363098145
Train loss: 10.320211505889892
Train loss: 11.73772211074829
Train loss: 11.523782014846802
Train loss: 9.005369901657104
Train loss: 11.039718198776246
Train loss: 10.310560512542725
Train loss: 10.636825275421142
Train loss: 9.7977303981781
Train loss: 10.299385452270508
Train loss: 11.49295449256897
Train loss: 10.443035745620728
Train loss: 11.040801382064819
Train loss: 11.993455028533935
Train loss: 11.311486196517944
Train loss: 9.743103885650635
Train loss: 9.479980421066283
Train loss: 9.669816064834595
Train loss: 10.70052433013916
Train loss: 11.883156156539917
Train loss: 11.35044984817505
Train loss: 10.24298815727234
Train loss: 9.587151670455933
Train loss: 11.07602949142456
Train loss: 11.31847038269043
Train loss: 10.327554512023926
Train loss: 11.148755311965942
Train loss: 10.693780088424683
Train loss: 12.218987369537354
Train loss: 10.569504070281983
Train loss: 11.813144207000732
Train loss: 10.135130310058594
Train loss: 12.198153257369995
Train loss: 10.146107006072999
Train loss: 11.224288415908813
Train loss: 9.819163608551026
Train loss: 9.320713806152344
Train loss: 10.96985740661621
Train loss: 10.71944169998169
Train loss: 11.560101795196534
Train loss: 9.385544157028198
Epoch 6, Loss: 10.886116919612885, Val Loss: 10.795369885184549, Time Elapsed: 9.21
Train loss: 20.520671844482422
Train loss: 9.179397630691529
Train loss: 10.899361753463745
Train loss: 10.159414958953857
Train loss: 9.976564407348633
Train loss: 9.82697148323059
Train loss: 10.96231164932251
Train loss: 12.286113929748534
Train loss: 11.690308761596679
Train loss: 10.537958526611328
Train loss: 11.872556161880492
Train loss: 9.908947229385376
Train loss: 10.490734624862672
Train loss: 9.714771461486816
Train loss: 10.798746967315674
Train loss: 9.52552409172058
Train loss: 10.877844905853271
Train loss: 11.405634355545043
Train loss: 11.62577543258667
Train loss: 11.591819143295288
Train loss: 11.681705284118653
Train loss: 9.801177406311036
Train loss: 11.028436326980591
Train loss: 10.88093957901001
Train loss: 10.835907649993896
Train loss: 12.26762776374817
Train loss: 10.18356533050537
Train loss: 11.46160340309143
Train loss: 11.00213394165039
Train loss: 10.104279565811158
Train loss: 12.526487159729005
Train loss: 10.47197585105896
Train loss: 10.068972158432008
Train loss: 11.23723840713501
Train loss: 12.215477752685548
Train loss: 11.291583919525147
Train loss: 11.743989610671997
Train loss: 10.280363988876342
Train loss: 10.61752347946167
Train loss: 11.305858421325684
Train loss: 11.573267078399658
Train loss: 12.862201595306397
Train loss: 12.322584342956542
Train loss: 11.997646522521972
Train loss: 11.180006074905396
Train loss: 10.397648286819457
Train loss: 10.674300575256348
Train loss: 10.447848987579345
Train loss: 11.747802352905273
Train loss: 11.616562604904175
Epoch 7, Loss: 11.017041751289367, Val Loss: 11.04240648876537, Time Elapsed: 8.79
Train loss: 12.907832145690918
Train loss: 11.706639575958253
Train loss: 11.679302883148193
Train loss: 9.992094802856446
Train loss: 11.987519359588623
Train loss: 11.30492844581604
Train loss: 9.521938276290893
Train loss: 12.602161884307861
Train loss: 10.307824945449829
Train loss: 9.384865999221802
Train loss: 11.7230815410614
Train loss: 12.597590589523316
Train loss: 9.047630834579468
Train loss: 10.070232915878297
Train loss: 9.97068886756897
Train loss: 12.859041595458985
Train loss: 13.54316554069519
Train loss: 10.90589017868042
Train loss: 11.101866722106934
Train loss: 10.943202352523803
Train loss: 10.69616403579712
Train loss: 10.472081899642944
Train loss: 10.672852993011475
Train loss: 11.230484056472779
Train loss: 11.691604948043823
Train loss: 10.712829113006592
Train loss: 11.220874881744384
Train loss: 10.254060125350952
Train loss: 9.317289972305298
Train loss: 12.807203769683838
Train loss: 13.051015043258667
Train loss: 9.898578548431397
Train loss: 11.059263610839844
Train loss: 12.728796100616455
Train loss: 11.817290925979615
Train loss: 11.29399209022522
Train loss: 10.492095041275025
Train loss: 10.410483837127686
Train loss: 10.696899795532227
Train loss: 11.488479709625244
Train loss: 10.063286781311035
Train loss: 9.38312120437622
Train loss: 12.38526759147644
Train loss: 9.432868003845215
Train loss: 12.442771482467652
Train loss: 10.635871410369873
Train loss: 12.186274433135987
Train loss: 9.528769731521606
Train loss: 12.73013687133789
Train loss: 10.210998439788819
Epoch 8, Loss: 11.167623821353912, Val Loss: 10.621210896752098, Time Elapsed: 8.88
Train loss: 12.373819351196289
Train loss: 11.33238730430603
Train loss: 11.529607343673707
Train loss: 10.325972414016723
Train loss: 10.458400058746339
Train loss: 10.397807264328003
Train loss: 9.418974685668946
Train loss: 11.555879592895508
Train loss: 9.602549982070922
Train loss: 11.964425659179687
Train loss: 10.620097160339355
Train loss: 9.97837142944336
Train loss: 10.369343614578247
Train loss: 8.68876371383667
Train loss: 12.233227348327636
Train loss: 10.226560878753663
Train loss: 11.242940855026244
Train loss: 11.531687116622924
Train loss: 10.434775447845459
Train loss: 10.639731454849244
Train loss: 11.355017852783202
Train loss: 9.8900550365448
Train loss: 11.016199207305908
Train loss: 11.618127298355102
Train loss: 12.461358070373535
Train loss: 12.084311580657959
Train loss: 11.603694629669189
Train loss: 10.730502510070801
Train loss: 11.396841382980346
Train loss: 11.234140110015868
Train loss: 13.507391548156738
Train loss: 12.074865341186523
Train loss: 12.169150733947754
Train loss: 9.62672691345215
Train loss: 11.149095487594604
Train loss: 11.278328132629394
Train loss: 10.780180263519288
Train loss: 12.285667562484742
Train loss: 9.920994853973388
Train loss: 10.263012886047363
Train loss: 11.264735794067382
Train loss: 12.37681450843811
Train loss: 11.17945318222046
Train loss: 11.586046123504639
Train loss: 9.798765611648559
Train loss: 11.465603733062744
Train loss: 12.243643856048584
Train loss: 12.431600570678711
Train loss: 10.829086112976075
Train loss: 9.141993999481201
Epoch 9, Loss: 11.050344169139862, Val Loss: 11.356156184456566, Time Elapsed: 8.76
Traceback (most recent call last):
  File "/Users/apple/Desktop/Classes/2026 Spring/NLP/Homeworks/HW1/hw1/word2vec/train.py", line 277, in <module>
    train(model, train_dataset, validation_dataset, vocab, wandb_online=use_wandb)
    ~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/apple/Desktop/Classes/2026 Spring/NLP/Homeworks/HW1/hw1/word2vec/train.py", line 242, in train
    reduced_embeddings = reduce_dimensions(model.get_embeddings(), d=2)
  File "/Users/apple/Desktop/Classes/2026 Spring/NLP/Homeworks/HW1/hw1/word2vec/word2vec_utils.py", line 73, in reduce_dimensions
    reduced_embeddings = tsne.fit_transform(embeddings)
  File "/Users/apple/Desktop/Classes/2026 Spring/NLP/Homeworks/HW1/hw1/.venv/lib/python3.14/site-packages/sklearn/utils/_set_output.py", line 316, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/Users/apple/Desktop/Classes/2026 Spring/NLP/Homeworks/HW1/hw1/.venv/lib/python3.14/site-packages/sklearn/base.py", line 1336, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/Users/apple/Desktop/Classes/2026 Spring/NLP/Homeworks/HW1/hw1/.venv/lib/python3.14/site-packages/sklearn/manifold/_t_sne.py", line 1136, in fit_transform
    embedding = self._fit(X)
  File "/Users/apple/Desktop/Classes/2026 Spring/NLP/Homeworks/HW1/hw1/.venv/lib/python3.14/site-packages/sklearn/manifold/_t_sne.py", line 1026, in _fit
    return self._tsne(
           ~~~~~~~~~~^
        P,
        ^^
    ...<4 lines>...
        skip_num_points=skip_num_points,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/apple/Desktop/Classes/2026 Spring/NLP/Homeworks/HW1/hw1/.venv/lib/python3.14/site-packages/sklearn/manifold/_t_sne.py", line 1094, in _tsne
    params, kl_divergence, it = _gradient_descent(obj_func, params, **opt_args)
                                ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/apple/Desktop/Classes/2026 Spring/NLP/Homeworks/HW1/hw1/.venv/lib/python3.14/site-packages/sklearn/manifold/_t_sne.py", line 400, in _gradient_descent
    error, grad = objective(p, *args, **kwargs)
                  ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^
  File "/Users/apple/Desktop/Classes/2026 Spring/NLP/Homeworks/HW1/hw1/.venv/lib/python3.14/site-packages/sklearn/manifold/_t_sne.py", line 281, in _kl_divergence_bh
    error = _barnes_hut_tsne.gradient(
        val_P,
    ...<9 lines>...
        num_threads=num_threads,
    )
KeyboardInterrupt
